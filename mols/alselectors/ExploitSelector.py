from typing import Any, List, Tuple, Dict
import numpy as np
import logging

from utils.Selector import Selector

class ExploitSelector(Selector):
    """Exploitation-based selection strategy for active learning.
    
    Selects samples with highest predicted values, optionally weighted by confidence.
    Useful for focusing on compounds with high predicted activity.
    """
    
    def __init__(self, batch_size: int, random_seed: int, **kwargs: Any) -> None:
        """Initialize ExploitSelector.
        
        Args:
            batch_size: Number of samples to select per AL cycle
            random_seed: Random seed for reproducibility
            **kwargs: Additional parameters
                - use_confidence: Whether to weight predictions by confidence (default: True)
                - confidence_threshold: Minimum confidence threshold (default: 0.0)
        """
        super().__init__(batch_size, random_seed, **kwargs)
        self.confidence_threshold = kwargs.get('confidence_threshold', 0.0)
        self.use_confidence = kwargs.get('use_confidence', False)
        
        # Log initialization
        self.logger.info(f"Initialized ExploitSelector with batch_size={batch_size}")
        self.logger.info(f"Confidence threshold: {self.confidence_threshold}")
        self.logger.info(f"Use confidence weighting: {self.use_confidence}")
    
    def _compute_exploitation_scores(
        self,
        predictions: np.ndarray,
        confidence_scores: np.ndarray
    ) -> np.ndarray:
        """Compute exploitation scores for each sample.
        
        Args:
            predictions: Model predictions (1D array)
            confidence_scores: Model confidence scores (1D array)
            
        Returns:
            Array of exploitation scores
        """
        # Ensure inputs are 1D arrays
        predictions = predictions.reshape(-1)
        confidence_scores = confidence_scores.reshape(-1)
        
        if self.use_confidence:
            # Weight predictions by confidence
            self.logger.debug("Computing weighted exploitation scores using confidence")
            return predictions * confidence_scores
        else:
            # Use raw predictions
            self.logger.debug("Computing raw exploitation scores")
            return predictions
    
    def select(
        self,
        predictions: np.ndarray,
        confidence_scores: np.ndarray,
        training_data: Tuple[Dict[str, np.ndarray], np.ndarray],
        unlabeled_data: Dict[str, np.ndarray],
        random_seed: int,
        **kwargs: Any
    ) -> List[int]:
        """Select samples with highest predicted values.
        
        Args:
            predictions: Model predictions (1D array)
            confidence_scores: Model confidence scores (1D array)
            training_data: Current training set (features_dict, labels) (not used in exploitation selection)
            unlabeled_data: Dictionary of unlabeled features, where keys are feature names and values are feature arrays.
                           Must contain 'SMILES' key with SMILES strings.
            random_seed: Random seed for reproducibility
            **kwargs: Additional parameters
            
        Returns:
            List of selected sample indices
        """
        # Ensure inputs are 1D arrays
        predictions = predictions.reshape(-1)
        confidence_scores = confidence_scores.reshape(-1)
        
        if 'SMILES' not in unlabeled_data:
            raise ValueError("unlabeled_data must contain 'SMILES' key")
        
        n_samples = len(unlabeled_data['SMILES'])
        if n_samples < self.batch_size:
            self.logger.error(f"Not enough unlabeled samples ({n_samples}) for batch size {self.batch_size}")
            raise ValueError(
                f"Not enough unlabeled samples ({n_samples}) for batch size {self.batch_size}"
            )
        
        # Validate input shapes
        if len(predictions) != n_samples or len(confidence_scores) != n_samples:
            self.logger.error(
                f"Shape mismatch: predictions ({len(predictions)}), "
                f"confidence_scores ({len(confidence_scores)}), "
                f"unlabeled_data SMILES ({n_samples})"
            )
            raise ValueError(
                f"Shape mismatch: predictions ({len(predictions)}), "
                f"confidence_scores ({len(confidence_scores)}), "
                f"unlabeled_data SMILES ({n_samples})"
            )
        
        self.logger.info(f"Starting exploitation selection from {n_samples} candidates")
        
        # Compute exploitation scores
        exploitation_scores = self._compute_exploitation_scores(predictions, confidence_scores)
        
        # Apply confidence threshold if specified
        if self.confidence_threshold > 0:
            mask = confidence_scores >= self.confidence_threshold
            n_valid = np.sum(mask)
            self.logger.info(f"Applied confidence threshold {self.confidence_threshold}: {n_valid} valid samples")
            
            if n_valid < self.batch_size:
                self.logger.error(
                    f"Not enough samples ({n_valid}) meet confidence threshold "
                    f"{self.confidence_threshold} for batch size {self.batch_size}"
                )
                raise ValueError(
                    f"Not enough samples ({n_valid}) meet confidence threshold "
                    f"{self.confidence_threshold} for batch size {self.batch_size}"
                )
            exploitation_scores = exploitation_scores[mask]
            valid_indices = np.where(mask)[0]
        else:
            valid_indices = np.arange(len(exploitation_scores))
        
        # Select indices with highest exploitation scores
        top_indices = np.argsort(exploitation_scores)[-self.batch_size:]
        selected_indices = valid_indices[top_indices].tolist()
        
        self.logger.info(f"Selected {len(selected_indices)} candidates")
        self.logger.debug(f"Selected indices: {selected_indices}")
        self.logger.debug(f"Exploitation scores range: {exploitation_scores[top_indices].min():.3f} to {exploitation_scores[top_indices].max():.3f}")
        
        return selected_indices 