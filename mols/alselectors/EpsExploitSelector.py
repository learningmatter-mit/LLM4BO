from typing import Any, List, Tuple, Dict
import numpy as np
from numpy.random import default_rng
import logging

from utils.Selector import Selector


class EpsExploitSelector(Selector):
    """Epsilon-greedy selection strategy for active learning.

    For batch selection, first draw the number of random picks k from
    Binomial(batch_size, epsilon). Select k candidates uniformly at random
    from the entire pool, then fill the remaining batch_size - k slots with
    greedy picks having the highest predicted values among the remaining
    candidates.
    """

    def __init__(self, batch_size: int, random_seed: int, **kwargs: Any) -> None:
        """Initialize EpsExploitSelector.

        Args:
            batch_size: Number of samples to select per AL cycle
            random_seed: Random seed for reproducibility
            **kwargs: Additional parameters
                - epsilon: Probability of random selection per candidate (default: 0.05)
        """
        super().__init__(batch_size, random_seed, **kwargs)

        self.epsilon = float(kwargs.get("epsilon", 0.05))
        if not (0.0 <= self.epsilon <= 1.0):
            raise ValueError("epsilon must be in [0.0, 1.0]")
        self.rng = default_rng(random_seed)

        # Log initialization
        self.logger.info(
            f"Initialized EpsExploitSelector with batch_size={batch_size}, epsilon={self.epsilon}"
        )

    def select(
        self,
        predictions: np.ndarray,
        confidence_scores: np.ndarray,
        training_data: Tuple[Dict[str, np.ndarray], np.ndarray],
        unlabeled_data: Dict[str, np.ndarray],
        random_seed: int,
        **kwargs: Any,
    ) -> List[int]:
        """Select samples via epsilon-greedy.

        Draw k ~ Binomial(batch_size, epsilon). Pick k random samples from the
        entire pool, then pick the remaining batch_size - k greedily by highest
        predictions among the not-yet-selected candidates.

        Args:
            predictions: Model predictions (1D array)
            confidence_scores: Unused (accepted for interface compatibility)
            training_data: Current training set (features_dict, labels) (unused)
            unlabeled_data: Dict of unlabeled features; must contain 'SMILES'
            random_seed: Random seed for reproducibility (unused; instance RNG is used)
            **kwargs: Additional parameters (unused)

        Returns:
            List of selected sample indices of length `batch_size`.
        """
        # Basic validations
        if "SMILES" not in unlabeled_data:
            raise ValueError("unlabeled_data must contain 'SMILES' key")

        n_samples = len(unlabeled_data["SMILES"])
        if n_samples < self.batch_size:
            self.logger.error(
                f"Not enough unlabeled samples ({n_samples}) for batch size {self.batch_size}"
            )
            raise ValueError(
                f"Not enough unlabeled samples ({n_samples}) for batch size {self.batch_size}"
            )

        predictions = predictions.reshape(-1)
        if len(predictions) != n_samples:
            self.logger.error(
                f"Shape mismatch: predictions ({len(predictions)}), unlabeled_data SMILES ({n_samples})"
            )
            raise ValueError(
                f"Shape mismatch: predictions ({len(predictions)}), unlabeled_data SMILES ({n_samples})"
            )

        self.logger.info(f"Starting epsilon-greedy selection from {n_samples} candidates")

        # Sample number of random picks from Binomial(batch_size, epsilon)
        num_random = int(self.rng.binomial(self.batch_size, self.epsilon)) if self.epsilon > 0 else 0
        num_random = min(max(num_random, 0), self.batch_size)
        num_greedy = self.batch_size - num_random

        all_indices = np.arange(n_samples)

        # Random selection from the entire pool (no replacement)
        random_selected: List[int] = []
        if num_random > 0:
            random_choices = self.rng.choice(all_indices, size=num_random, replace=False)
            random_selected = random_choices.tolist()

        # Greedy selection among remaining candidates by highest predictions
        greedy_selected: List[int] = []
        if num_greedy > 0:
            if random_selected:
                remaining_indices = np.setdiff1d(all_indices, np.array(random_selected), assume_unique=False)
            else:
                remaining_indices = all_indices

            remaining_predictions = predictions[remaining_indices]
            # Select indices with highest predictions among remaining
            if num_greedy >= remaining_predictions.size:
                top_within_remaining = np.arange(remaining_predictions.size)
            else:
                top_within_remaining = np.argsort(remaining_predictions)[-num_greedy:]
            greedy_selected = remaining_indices[top_within_remaining].tolist()

        selected_indices = greedy_selected + random_selected

        # Final sanity check
        if len(selected_indices) != self.batch_size:
            self.logger.error(
                f"Internal selection size mismatch: expected {self.batch_size}, got {len(selected_indices)}"
            )
            raise RuntimeError(
                f"Internal selection size mismatch: expected {self.batch_size}, got {len(selected_indices)}"
            )

        self.logger.info(f"Selected {len(selected_indices)} candidates")
        self.logger.info(f"Random count: {len(random_selected)}, Greedy count: {len(greedy_selected)}")
        self.logger.debug(f"Selected indices: {selected_indices}")

        return selected_indices


